{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('Harry_Potter80_filled.db')\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = input('Введите запрос: ')\n",
    "request_items = re.split(' ', request)\n",
    "print(request_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "это запрос для двух частей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "select * FROM\n",
    "\n",
    "\n",
    "(\n",
    "select texts.title, b.sentence, t.word as first,\n",
    "\n",
    "   (select s.word\n",
    "   from tokens s\n",
    "   join main on s.token_id = main.token_id\n",
    "   join sentences p on p.sentence_id = main.sentence_id\n",
    "   where s.token_id = t.token_id + 1\n",
    "   and b.sentence_id = p.sentence_id\n",
    "   and s.pos = 'VERB' -- \n",
    "   ) second\n",
    "\n",
    "from \n",
    "  tokens t\n",
    "  join main on t.token_id = main.token_id\n",
    "  join sentences b on b.sentence_id = main.sentence_id\n",
    "  join texts on b.text_id = texts.text_id\n",
    "where t.pos = 'NOUN' -- \n",
    ")\n",
    "\n",
    "\n",
    "where not (second is null)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06868124008178711\n"
     ]
    }
   ],
   "source": [
    "time1 = time.time()\n",
    "cur.execute(query)\n",
    "len(cur.fetchall())\n",
    "print(time.time()-time1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "это запрос для трех частей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''select * FROM\n",
    "\n",
    "(\n",
    "select t.token_id, t.word,\n",
    "  (select s.word\n",
    "   from tokens s\n",
    "   where s.token_id = t.token_id + 1\n",
    "   and s.pos = 'NOUN') second, \n",
    "  \n",
    "  (select s.word\n",
    "   from tokens s\n",
    "   where s.token_id = t.token_id + 2\n",
    "   and s.pos = 'NOUN') third \n",
    "\n",
    "from \n",
    "  tokens t\n",
    "where t.pos = 'NOUN'\n",
    ")\n",
    "\n",
    "where not (second is null or third is null)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Для двух"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "first_part = '''select * FROM\n",
    "(\n",
    "select texts.title, b.sentence, t.word as first,\n",
    "  (select s.word\n",
    "   from tokens s\n",
    "   join main on s.token_id = main.token_id\n",
    "   join sentences p on p.sentence_id = main.sentence_id\n",
    "   where s.token_id = t.token_id + 1\n",
    "   and s'''\n",
    "\n",
    "# 's.pos = \"VERB\"'\n",
    "\n",
    "second_part = '''and b.sentence_id = p.sentence_id\n",
    "   ) second\n",
    "from \n",
    "  tokens t\n",
    "  join main on t.token_id = main.token_id\n",
    "  join sentences b on b.sentence_id = main.sentence_id\n",
    "  join texts on b.text_id = texts.text_id\n",
    "  where t.'''\n",
    "\n",
    "# 'where t.pos = \"NOUN\"'\n",
    "\n",
    "third_part = ''')\n",
    "where not (second is null)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Введите запрос: NOUN VERB\n",
      "['NOUN', 'VERB']\n"
     ]
    }
   ],
   "source": [
    "request = input('Введите запрос: ')\n",
    "request_items = re.split(' ', request)\n",
    "print(request_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in request_items:\n",
    "    for_item = ''\n",
    "    if '\"' in item:\n",
    "        exact_form = re.search('[а-яА-ЯёЁ]+', item)[0]\n",
    "        for_item = '.word = ' + exact_form\n",
    "        query = first_part + for_item + second_part + ___ + \n",
    "\n",
    "    elif item in poss:\n",
    "        cur.execute(pos_sql, [item,])\n",
    "        data = cur.fetchall()\n",
    "\n",
    "    elif '+' in item:\n",
    "        word = re.search('[а-яА-ЯёЁ]+', item)[0] # можно было сплитнуть по плюсу но ладно\n",
    "        pos = re.search('[A-Z]+', item)[0]\n",
    "        doc = Doc(word)\n",
    "        doc.segment(segmenter)\n",
    "        doc.tag_morph(morph_tagger)\n",
    "        for token in doc.tokens:\n",
    "            token.lemmatize(morph_vocab)\n",
    "            lemma = token.lemma\n",
    "            cur.execute(word_pos_sql, [lemma, pos])\n",
    "        data = cur.fetchall()\n",
    "\n",
    "    else:\n",
    "        doc = Doc(item)\n",
    "        doc.segment(segmenter)\n",
    "        doc.tag_morph(morph_tagger)\n",
    "        for token in doc.tokens:\n",
    "            token.lemmatize(morph_vocab)\n",
    "            lemma = token.lemma\n",
    "            cur.execute(lemma_sql, [lemma,])\n",
    "        data = cur.fetchall()\n",
    "    return data\n",
    "\n",
    "query = first_part + for_item1 + second_part + for_item2 + third_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
